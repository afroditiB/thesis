!pip install -U darts
!pip install -U optuna
!pip install -U matplotlib

%matplotlib inline

import torch
import random
import numpy as np
from darts import TimeSeries
import pandas as pd
import matplotlib.pyplot as plt
from tqdm.notebook import tqdm
from pytorch_lightning.callbacks import Callback, EarlyStopping
from sklearn.preprocessing import MaxAbsScaler, StandardScaler, MinMaxScaler

from sklearn.metrics import mean_absolute_percentage_error as mape
from sklearn.metrics import mean_squared_error as mse
from darts.metrics import mape as mape_darts
from darts.metrics import mase as mase_darts
from darts.metrics import mae as mae_darts
from darts.metrics import rmse as rmse_darts
from darts.metrics import smape as smape_darts


from darts.datasets import ElectricityDataset
from darts.models import TCNModel, LinearRegressionModel, LightGBMModel, NBEATSModel
from darts.dataprocessing.transformers import Scaler
from darts.metrics import smape, rmse, mape, mae, mase
from darts.utils.likelihood_models import GaussianLikelihood
import datetime
from datetime import timedelta

import logging
from functools import reduce

def select_range(df,start_date,end_date):
  """
  Parameters: df : pd.Dataframe : the dataframe that we want to check for missing datetime values
              start_date : str : the desired start date of our df
              end_date : str : the desired end_date of our df

  Returns : ts : the cut df from start_date to end_date
"""
  ts=df.copy()
  start = pd.Timestamp(start_date)
  end = pd.Timestamp(end_date)
  ts=ts.loc[start:end]
  return ts

def read_csv_and_set_index(file,col=None,format=None,date_parse=None, separator = None):
  """
   Parameters: file : str: the name of the csv file that we want to save as df
               col : str : the name of the column we want to set as index
            
   Returns : df : pd.DataFrame : the df from the csv file, with col as index
"""
  if (date_parse is not None):
    dateparse = lambda x: datetime.datetime.strptime(x, '%Y%m%d%H%M%S')
    parse = [col]
  else :
    parse = False
    dateparse = None

  df = pd.read_csv(file,parse_dates=parse, date_parser=dateparse,sep=separator)
  if (col is not None):
    df = df.set_index(col)
  df.index=pd.to_datetime(df.index)
  return df


def convert_to_timeseries(df,col=None, resolution=None):

  """"
    Parameters: df : pd.DataFrame : the df we want to convert to TimeSeries
                resolution : str : the resolution in which we want to resample
                col : [str] : the column which we want to convert to TimeSeries, if not None, inside brackets
            
   Returns : series : TimeSeries: the converted timeseries from df or df's columns ( if col is not None)
  
"""
  if(resolution is not None):
    df=df.resample(resolution).mean()

  if (col is not None):
    data = df[col]
  else :
    data = df

  series = data.squeeze()
  series = series.astype(np.float32)
  series = TimeSeries.from_series(series)
  return series

def split_and_scale(series,test_start_date,scaler_model=None):

  """"
    Parameters: series : TimeSeries : The timeseries we want to split into train, val test and, optionally, scale.
                val_length : int : the length of the Timeseries we want to keep as a validation set
                scaler_model : sklearn.preprocessing. : the model of scaler to be fitted in our data.
            
   Returns : train : darts.TimeSeries: the timeseries we will use as a training set, meaning the input series timeseries, but cut at the val_start_date
             val   : TimeSeries: the timeseries we will use as a validation set, meaning the input series timeseries, but startint from the val_start_date
            series_transformed : TimeSeries : The timeseries with the scaled_model fitted and transformed
"""

  if (scaler_model is not None):
    scaler = Scaler(scaler=scaler_model)
    scaler_x =scaler.fit(series)
    series_transformed = scaler_x.transform(series)       

  else : 
    scaler_x = None
    series_transformed = series
  
  train = series_transformed.drop_after(pd.Timestamp(test_start_date))
  val = series_transformed.drop_before(pd.Timestamp(pd.Timestamp(
        test_start_date) - datetime.timedelta(hours=1)))
  
  return train,val, series_transformed, scaler_x

def append(x, y):
    return x.append(y)


def backtester_final(model,
               series_transformed,
               test_start_date,
               forecast_horizon,
               stride=None,
               series=None,
               transformer_ts=None,
               retrain=False,
               future_covariates=None,
               past_covariates=None,
               path_to_save_backtest=None):
    """ Does the same job with advanced forecast but much more quickly using the darts
    bult-in historical_forecasts method. Use this for evaluation. The other only
    provides pure inference. Provide a unified timeseries test set point based
    on test_start_date. series_transformed does not need to be adjacent to
    training series. if transformer_ts=None then no inverse transform is applied
    to the model predictions.
    Parameters
    ----------
    Returns
    ----------
    """
    # produce the fewest forecasts possible.
    if stride is None:
        stride = forecast_horizon
    test_start_date = pd.Timestamp(test_start_date)
    from functools import reduce

    # produce list of forecasts
    #print("backtesting starting at", test_start_date, "series:", series_transformed)
    backtest_series_transformed = model.historical_forecasts(series_transformed,
                                                             future_covariates=future_covariates,
                                                             past_covariates=past_covariates,
                                                             start=test_start_date,
                                                             forecast_horizon=forecast_horizon,
                                                             stride=stride,
                                                             retrain=retrain,
                                                             last_points_only=False,
                                                             verbose=False)
    


    # flatten lists of forecasts due to last_points_only=False
    if isinstance(backtest_series_transformed, list):
        backtest_series_transformed = reduce(
            append, backtest_series_transformed)

    # inverse scaling
    if transformer_ts is not None:
        backtest_series = transformer_ts.inverse_transform(
            backtest_series_transformed)
        series = transformer_ts.inverse_transform(
            series_transformed)
    else:
        series = series_transformed
        backtest_series = backtest_series_transformed
        print("\nWarning: Scaler not provided. Ensure model provides normal scale predictions")
        logging.info(
            "\n Warning: Scaler not provided. Ensure model provides normal scale predictions")

    # plot all test
    fig1 = plt.figure(figsize=(15, 8))
    ax1 = fig1.add_subplot(111)
    backtest_series.plot(label='forecast')
    series \
        .drop_before(pd.Timestamp(pd.Timestamp(test_start_date) - datetime.timedelta(days=7))) \
        .drop_after(backtest_series.time_index[-1]) \
        .plot(label='actual')
    ax1.legend()
    ax1.set_title(
        f'Backtest, starting {test_start_date}, {forecast_horizon}-steps horizon')
    # plt.show()

    # plot one week (better visibility)
    forecast_start_date = pd.Timestamp(
        test_start_date + datetime.timedelta(days=7))

    fig2 = plt.figure(figsize=(15, 8))
    ax2 = fig2.add_subplot(111)
    backtest_series \
        .drop_before(pd.Timestamp(forecast_start_date)) \
        .drop_after(forecast_start_date + datetime.timedelta(days=7)) \
        .plot(label='Forecast')
    series \
        .drop_before(pd.Timestamp(forecast_start_date)) \
        .drop_after(forecast_start_date + datetime.timedelta(days=7)) \
        .plot(label='Actual')
    ax2.legend()
    ax2.set_title(
        f'Weekly forecast, Start date: {forecast_start_date}, Forecast horizon (timesteps): {forecast_horizon}, Forecast extended with backtesting...')

    # Metrix
    test_series =  series.drop_before(pd.Timestamp(pd.Timestamp(
        test_start_date) - datetime.timedelta(hours=1)))
    metrics = {
        
        "smape": smape_darts(
            test_series,
            backtest_series),
        "mase": mase_darts(
            test_series,
            backtest_series,
            insample=series.drop_after(pd.Timestamp(test_start_date))),
        "mae": mae_darts(
            test_series,
            backtest_series),
        "rmse": rmse_darts(
            test_series,
            backtest_series),
        "mape" : mape_darts(abs(test_series),
            abs(backtest_series))
    }

    

    for key, value in metrics.items():
        print(key, ': ', value)



    return {"metrics": metrics, "eval_plot": plt, "backtest_series": backtest_series}

power =read_csv_and_set_index('power_dt.csv','index')
current =read_csv_and_set_index('current_dt.csv','index')
voltage =read_csv_and_set_index('voltage_dt.csv','index')
weather = read_csv_and_set_index('weather.csv',col='time [UTC](yyyymmddHHMM)',date_parse = True, separator =';')

!!If we want to change timezone!!Convert UTC to local Terni Time, so for the winter months the weather's timestamp will be shifted one hour ahead ( Timezone Italy = UTC +1 ) and for the summer months two hours ahead ( Timezone Italy = UTC + 2 )


weather=weather.reset_index()

with tz.localize we make the pd.Df timezone aware, timezone doesn't change with localize
with tz.covert will convert the timestamps to the selected timezone, here Europe/ Italy



weather['time [UTC](yyyymmddHHMM)'] = pd.to_datetime(weather['time [UTC](yyyymmddHHMM)']) \
                             .dt.tz_localize('UTC') \
                             .dt.tz_convert('Europe/Rome')

weather['time [UTC](yyyymmddHHMM)']=pd.to_datetime(weather['time [UTC](yyyymmddHHMM)']).dt.tz_localize(None)

weather= weather.set_index('time [UTC](yyyymmddHHMM)')


Selecting range and converting dfs to Timeseries

start ='2021-08-06 17:00:00'
end = '2022-07-03 17:00:00'
power = select_range(power,start,end)
current=select_range(current,start,end)
voltage = select_range(voltage,start,end)
weather = select_range(weather,start,end)


power = power.interpolate()
current = current.interpolate()
voltage  = voltage.interpolate()


series = convert_to_timeseries(power,['active_w6'],'60min')

Spliting our series at train / val sets and start trying forecasting models


train, val, series_transformed, scaler = split_and_scale(series, '2022-06-03 17:00:00', MinMaxScaler())

lgbm_model_power = LightGBMModel(lags = 10*24)
lgbm_model_power.fit(train)

backtest_dict = backtester_final(lgbm_model_power,series_transformed,'2022-06-03 17:00:00',3, series=series,transformer_ts=scaler )

test_series = series.drop_before(pd.Timestamp(pd.Timestamp(pd.Timestamp(
        '2022-06-03 17:00:00') - datetime.timedelta(hours=1))))

backtest_series = backtest_dict.get("backtest_series")

weather_rad=convert_to_timeseries(weather,'global radiation [W/m^2]','60min')
weather_humidity = convert_to_timeseries(weather,'relative humidity [%]','60min')
weather_temp = convert_to_timeseries(weather,'air temperature [°C]','60min')
weather_cloud = convert_to_timeseries(weather,'cloudcover [%]','60min')
weather_wind = convert_to_timeseries(weather,'wind speed[m/s]','60min')


test_series[-60:].plot(label='actual')
backtest_series[-60:].plot(label='forecast')
weather_rad[-60:].pd_dataframe().plot(label='weather')


plt.plot(weather_rad.pd_dataframe()['2022-06-22 00:00:00':'2022-06-25 00:00:00'], label = 'weather')
plt.plot(series.pd_dataframe()['2022-06-22 00:00:00':'2022-06-25 00:00:00'], label='pv power')

plt.xticks(rotation = 45)
plt.legend()
plt.show()



plt.plot(backtest_series.pd_dataframe()['2022-06-22 00:00:00':'2022-06-25 00:00:00'], label = 'forecast')
plt.plot(series.pd_dataframe()['2022-06-22 00:00:00':'2022-06-25 00:00:00'], label='pv power')

plt.xticks(rotation = 45)
plt.legend()
plt.show()


weather_cov=weather_rad

train_cov,  val_cov, series_cov , sc_cov = split_and_scale(weather_cov,'2022-06-03 17:00:00',MinMaxScaler())

lgbm_model_power = LightGBMModel(lags = 10*24,lags_past_covariates = 1*24)
lgbm_model_power.fit(train, past_covariates = train_cov)
backtest_dict = backtester_final(lgbm_model_power,series_transformed,'2022-06-03 17:00:00',3, series=series,transformer_ts=scaler, past_covariates=series_cov)

backtest_series = backtest_dict.get("backtest_series")


plt.plot(backtest_series.pd_dataframe()['2022-06-19 00:00:00':'2022-06-25 22:00:00'], label = 'forecast')
plt.plot(series.pd_dataframe()['2022-06-19 00:00:00':'2022-06-25 22:00:00'], label='pv power')

plt.xticks(rotation = 45)
plt.legend()
plt.show()


hour_covariate = convert_to_timeseries(power,['hour_of_day'],'60min')
month_covariate = convert_to_timeseries(power,['month'],'60min')

past_covariates =weather_rad.stack(weather_temp).stack(hour_covariate).stack(month_covariate)

train_cov,  val_cov, series_cov ,sc_cov= split_and_scale(past_covariates,'2022-06-03 17:00:00',MinMaxScaler())


lgbm_model_power = LightGBMModel(lags = 10*24,lags_past_covariates = 1*24)
lgbm_model_power.fit(train, past_covariates = train_cov)
backtester_final(lgbm_model_power,series_transformed,'2022-06-03 17:00:00',3, series=series,transformer_ts=scaler, past_covariates=series_cov)

training1 =convert_to_timeseries(voltage,['w4_u3'],'60min')
train_extra1,  extra_val1, extra_series1 ,sc_cc = split_and_scale(training1,'2022-06-03 17:00:00',MinMaxScaler())

training2 = convert_to_timeseries(current,['w5_phase1'],'60min')
train_extra2,  extra_val2, extra_series2 ,sc_cc = split_and_scale(training2,'2022-06-03 17:00:00',MinMaxScaler())

training3 = convert_to_timeseries(power,['active_w4'],'60min')
train_extra3,  extra_val3, extra_series3 ,sc_cc = split_and_scale(training3,'2022-06-03 17:00:00',MinMaxScaler())



training = [ train, train_extra1,train_extra2,train_extra3]
training_cov = [ train_cov, train_cov,train_cov,train_cov]
series_covar = [series_cov, series_cov,series_cov,series_cov]

lgbm_model_power = LightGBMModel(lags = 10*24,lags_past_covariates = 1*24)
lgbm_model_power.fit(training[0:2], past_covariates = training_cov[0:2])

backtester_final(lgbm_model_power,series_transformed,'2022-06-03 17:00:00',3, series=series,transformer_ts=scaler, past_covariates=series_cov)
